{
  "pico_core": {
    "query": "\n    (Multi UAV OR autonomous drones OR UAV swarm OR unmanned aerial vehicle swarm OR autonomous UAV) AND\n    (multi-agent reinforcement learning OR deep reinforcement learning OR reinforcement learning OR deep learning OR neural networks OR MARL OR DRL) AND\n    (exploration OR avoidance OR planning OR formation OR coordination) AND\n    (performance OR efficiency OR adaptability OR robustness OR scalability)\n    ",
    "response": "Based on the search results provided, here are the peer-reviewed and preprint academic papers published between June 2024 and December 2025 that satisfy your PICO-based criteria for UAV swarm systems with reinforcement learning:\n\n---\n\n
    **1. Reinforcement Learning for Decision-Level Interception in UAV Swarm Defense**\n\n
    - **Authors:** Not explicitly provided in excerpt\n
    - **Year:** 2025\n
    - **Publication Venue:** arXiv preprint (arxiv.org/html/2508.00641v1)\n
    - **Main Contribution:** Presents a high-fidelity simulation environment where a decision-level reinforcement learning agent learns to coordinate multiple effectors for optimal interception prioritization against kamikaze drone swarms. The approach addresses centralized threat prioritization under noisy, partial observations and heterogeneous attack patterns, serving as a decision-support system rather than direct trajectory control.\n-
     **Task Addressed:** Threat prioritization, interception coordination, defense against swarm-based saturation attacks\n
     - **Learning Paradigm:** Centralized reinforcement learning with decision-level policy learning\n- **Evaluation Setup:** High-fidelity simulation environment capturing realistic operational constraints\n-
      **Link:** https://arxiv.org/html/2508.00641v1\n\n---\n\n**
      // 2. Supporting UAVs Swarm Missions by Multi-Agent Reinforcement Learning**\n\n
      // - **Authors:** P. Fusco, L. Porcelli, F. Palmieri, M. Ficco (Università degli Studi di Salerno)\n
      // - **Year:** 2025\n
      // - **Publication Venue:** 2025 Workshop on Computing, Networking and Communications (CNC)\n
      // - **Main Contribution:** Presents a Multi-Agent Reinforcement Learning (MARL)-based approach for computing optimal coverage paths of large regions by UAV swarms supported by mobile battery swapping stations. The framework optimizes energy consumption, reduces travel distance, and enables adaptive path planning in response to environmental changes and mission requirements.[2]\n
      // - **Task Addressed:** Area coverage path planning, energy efficiency optimization, battery management coordination\n- 
      // **Learning Paradigm:** Multi-Agent Reinforcement Learning (MARL); Proximal Policy Optimization (PPO) achieved best performance\n-
      //  **Evaluation Setup:** Simulation framework with three UAV agents and ground-based mobile battery swapping stations\n- 
      // **Link:** http://www.conf-icnc.org/2025/papers/p222-fusco.pdf\n\n
      // ---\n\n**3. Reinforcement Learning–Based UAV Swarm Fission–Fusion**
      // \n\n- **Authors:** Not explicitly provided in excerpt\n- **Year:** 2024 or 2025 (publication date not specified in excerpt)\n- **Publication Venue:** International Journal of Aerospace Engineering (Wiley)\n- **Main Contribution:** Presents a reinforcement learning–based approach for UAV swarm fission–fusion dynamics with real-world data integrated validation.[3]\n- **Task Addressed:** Swarm fission–fusion (dynamic reconfiguration and splitting/merging of swarm formations)\n-
      //  **Learning Paradigm:** Reinforcement learning\n-
      //  **Evaluation Setup:** Real-world data integrated validation\n-
      //  **Link:** https://onlinelibrary.wiley.com/doi/full/10.1155/ijae/7686417\n\n---\n\n
      
      // **4. A Deployable, Decentralized Hierarchical Reinforcement Learning Strategy for Trajectory Planning and Control of UAV Swarms**\n\n-
      //  **Authors:** Grant Phillips (and others not fully listed in excerpt)\n- **Year:** 2024\n- 
      // **Publication Venue:** AIAA (American Institute of Aeronautics and Astronautics) conference proceedings\n-
      //  **Main Contribution:** Details the implementation of a decentralized, theoretically proven reinforcement learning-based controller for real-world UAV swarms, addressing practical deployment challenges including communication and computation constraints on onboard hardware.[4]\n- 
      // **Task Addressed:** Trajectory planning and control, decentralized swarm coordination\n-
      //  **Learning Paradigm:** Decentralized hierarchical reinforcement learning\n-
      //  **Evaluation Setup:** Real-world swarm implementation (hardware deployment)\n- 
      // **Link:** https://arc.aiaa.org/doi/10.2514/6.2024-2761\n\n---\n\n
      
      
      // **5. End-to-End Multi-Task Reinforcement Learning-Based UAV Swarm**\n\n-
      //  **Authors:** Not explicitly provided in excerpt\n- 
      // **Year:** 2025 (inferred from search results)\n- 
      // **Publication Venue:** ACM Digital Library / Knowledge-Based Systems journal\n- 
      // **Main Contribution:** Proposes an innovative end-to-end multi-task reinforcement learning framework designed to enhance the security and operational stability of UAVs in swarm configurations.[5]\n- 
      // **Task Addressed:** Multi-task learning for UAV swarm security and operational stability\n- **Learning Paradigm:** End-to-end multi-task reinforcement learning\n- **Evaluation Setup:** Not specified in excerpt\n-
      //  **Link:** https://dl.acm.org/doi/10.1016/j.knosys.2025.113390\n\n---\n\n**6. Enhanced Multi-Agent Coordination Algorithm for Drone Swarm Patrolling**\n\n- 
      // **Authors:** Not explicitly provided in excerpt\n- **Year:** 2025\n-
      //  **Publication Venue:** Nature Scientific Reports\n-
      //  **Main Contribution:** Proposes an enhanced multi-agent swarm control algorithm (EN-MASCA) to solve the problem of efficient patrolling by drone swarms.[6]\n- 
      // **Task Addressed:** Patrolling and area coverage\n- **Learning Paradigm:** Multi-agent coordination algorithm\n- 
      // **Evaluation Setup:** Not specified in excerpt\n- 
      // **Link:** https://www.nature.com/articles/s41598-025-88145-7\n\n---\n\n
      // **Note:** The search results provide limited bibliographic details for some papers. For complete author lists, abstract information, and methodological details, direct access to the full papers via the provided links is recommended.",
    "timestamp": "2025-12-23T20:09:01.311799"
  },
  "pico_control_and_navigation": {
    "query": "\n    (Multi UAV OR autonomous drones OR UAV swarm OR unmanned aerial vehicle swarm OR autonomous UAV) AND\n    (multi-agent reinforcement learning OR deep reinforcement learning OR reinforcement learning OR deep learning OR neural networks OR MARL OR DRL) AND\n    (planning OR navigation OR collision avoidance OR formation control)\n    ",
    "response": "Based on the search results provided, here are the peer-reviewed and preprint academic papers published between June 2024 and December 2025 that satisfy your PICO-based criteria:\n\n---\n\n
    ## 1. Reinforcement Learning for Decision-Level Interception of Kamikaze Drone Swarms\n\n
    **Authors:** Not explicitly provided in excerpt\n\n
    **Year:** 2025\n\n
    **Publication Venue:** arXiv preprint (arxiv.org/html/2508.00641v1)\n\n
    **Main Contribution:** Introduces a high-fidelity simulation environment and decision-level reinforcement learning agent for coordinating multiple defensive effectors to prioritize interceptions of hostile UAV swarms. The approach learns optimal threat prioritization policies under noisy, partial observations and adapts to heterogeneous attack patterns, serving as a decision-support system rather than direct trajectory control.[1]\n\n
    **Task Addressed:** Threat prioritization and interception coordination in swarm-based saturation attacks\n\n
    **Learning Paradigm:** Centralized reinforcement learning for high-level decision-making with partial observability\n\n**Evaluation Setup:** High-fidelity 3D simulation environment capturing realistic operational constraints\n\n**Link:** https://arxiv.org/html/2508.00641v1\n\n---\n\n## 2. Reinforcement Learning–Based UAV Swarm Fission–Fusion with Real-World Data Integrated Validation\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025 (inferred from publication venue)\n\n**Publication Venue:** International Journal of Aerospace Engineering (Wiley)\n\n**Main Contribution:** Presents a reinforcement learning–based approach for UAV swarm fission–fusion dynamics with integrated real-world data validation.[2]\n\n**Task Addressed:** Swarm fission–fusion (dynamic reconfiguration and splitting/merging of swarm formations)\n\n**Learning Paradigm:** Reinforcement learning\n\n**Evaluation Setup:** Real-world data integrated validation\n\n**Link:** https://onlinelibrary.wiley.com/doi/full/10.1155/ijae/7686417\n\n---\n\n## 3. A Deployable, Decentralized Hierarchical Reinforcement Learning Strategy for Trajectory Planning and Control of UAV Swarms\n\n**Authors:** Grant Phillips, Justin M. Bradley, Chandima Fernando\n\n**Year:** 2024\n\n**Publication Venue:** AIAA conference (arc.aiaa.org/doi/10.2514/6.2024-2761)\n\n**Main Contribution:** Details implementation of a decentralized, theoretically proven reinforcement learning–based controller for real-world UAV swarms, addressing practical deployment challenges including communication and computational constraints that differ from simulation assumptions.[3]\n\n**Task Addressed:** Trajectory planning and control in multi-agent swarm systems\n\n**Learning Paradigm:** Decentralized hierarchical reinforcement learning\n\n**Evaluation Setup:** Real-world outdoor deployment beyond WiFi and motion capture systems\n\n**Link:** https://arc.aiaa.org/doi/10.2514/6.2024-2761\n\n---\n\n## 4. Supporting UAVs Swarm Missions by Multi-Agent Reinforcement Learning\n\n**Authors:** Fusco et al.\n\n**Year:** 2025\n\n**Publication Venue:** 2025 Workshop on Computing, Networking and Communications (CNC)\n\n**Main Contribution:** Presents a Multi-Agent Reinforcement Learning (MARL)–based strategy for energy-efficient coverage path planning of large regions by UAV swarms supported by mobile battery swapping stations. Implements advanced path optimization to reduce travel distance, optimize battery management, and minimize energy consumption while ensuring comprehensive area coverage.[4]\n\n**Task Addressed:** Coverage path planning with energy optimization and collision avoidance\n\n**Learning Paradigm:** Multi-Agent Reinforcement Learning (MARL); Proximal Policy Optimization (PPO) achieved best performance\n\n**Evaluation Setup:** Simulation framework with three UAV agents\n\n**Link:** http://www.conf-icnc.org/2025/papers/p222-fusco.pdf\n\n---\n\n## 5. Enhanced Multi-Agent Coordination Algorithm for Drone Swarm Patrolling\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Nature Scientific Reports\n\n**Main Contribution:** Proposes an enhanced multi-agent swarm control algorithm (EN-MASCA) combining Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms for the first time to optimize UAV swarm path planning and obstacle avoidance in complex agricultural scenarios, with a virtual navigator model to enhance environmental adaptability.[5]\n\n**Task Addressed:** Path planning, obstacle avoidance, and patrolling in complex environments\n\n**Learning Paradigm:** Hybrid approach combining DQN and PPO algorithms\n\n**Evaluation Setup:** Simulation environment (specific details not provided in excerpt)\n\n**Link:** https://www.nature.com/articles/s41598-025-88145-7\n\n---\n\n## 6. End-to-End Multi-Task Reinforcement Learning–Based UAV Swarm\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Knowledge-Based Systems (Elsevier)\n\n**Main Contribution:** Proposes an innovative end-to-end multi-task reinforcement learning framework designed to enhance the security and operational stability of UAV swarms.[6]\n\n**Task Addressed:** Multi-task learning for UAV swarm operations\n\n**Learning Paradigm:** End-to-end multi-task reinforcement learning\n\n**Evaluation Setup:** Not specified in excerpt\n\n**Link:** https://dl.acm.org/doi/10.1016/j.knosys.2025.113390\n\n---\n\n**Note:** Some bibliographic details (particularly author names and complete evaluation methodologies) are incomplete in the provided search results. For comprehensive citation information and full technical details, consult the original publications directly.",
    "timestamp": "2025-12-23T20:09:14.521695"
  },
  "pico_coordination_and_cooperation": {
    "query": "\n    (Multi UAV OR autonomous drones OR UAV swarm OR unmanned aerial vehicle swarm OR autonomous UAV) AND\n    (multi-agent reinforcement learning OR deep reinforcement learning OR reinforcement learning OR deep learning OR neural networks OR MARL OR DRL) AND\n    (coordination OR cooperation OR decentralized execution)\n    ",
    "response": "Based on the search results provided, here are the peer-reviewed and preprint academic papers published between June 2024 and December 2025 that satisfy your PICO-based criteria for UAV swarm coordination using reinforcement learning:\n\n---\n\n## 1. Reinforcement Learning for Decision-Level Interception in UAV Swarm Networks\n\n**Authors:** Not fully specified in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** arXiv preprint (arxiv.org/html/2508.00641v1)\n\n**Main Contribution:** Introduces a high-fidelity simulation environment and decision-level reinforcement learning agent for coordinating multiple defensive effectors to optimize interception prioritization against kamikaze drone swarms. The approach learns optimal policies through interaction with realistic simulators that replicate engagement conditions, addressing the limitations of traditional rule-based systems in adapting to complex, unpredictable threat environments.[1]\n\n**Task Addressed:** Threat prioritization and interception coordination in adversarial swarm scenarios\n\n**Learning Paradigm:** Centralized decision-level reinforcement learning for multi-effector coordination\n\n**Evaluation Setup:** High-fidelity 3D simulation environment with realistic operational constraints[1]\n\n**Link:** https://arxiv.org/html/2508.00641v1\n\n---\n\n## 2. Reinforcement Learning–Based UAV Swarm Fission–Fusion\n\n**Authors:** Not fully specified in excerpt\n\n**Year:** 2025 (inferred from publication venue)\n\n**Publication Venue:** International Journal of Aerospace Engineering (Wiley)\n\n**Main Contribution:** Presents a reinforcement learning–based approach for UAV swarm fission–fusion dynamics with real-world data integrated validation.[2]\n\n**Task Addressed:** Swarm fission–fusion (dynamic reconfiguration and splitting/merging of swarm formations)\n\n**Learning Paradigm:** Reinforcement learning for swarm reconfiguration\n\n**Evaluation Setup:** Real-world data integrated validation[2]\n\n**Link:** https://onlinelibrary.wiley.com/doi/full/10.1155/ijae/7686417\n\n---\n\n## 3. A Deployable, Decentralized Hierarchical Reinforcement Learning Strategy for Trajectory Planning and Control of UAV Swarms\n\n**Authors:** Grant Phillips, Justin M. Bradley, Chandima Fernando\n\n**Year:** 2024\n\n**Publication Venue:** AIAA conference (arc.aiaa.org/doi/10.2514/6.2024-2761)\n\n**Main Contribution:** Details the implementation of a decentralized, theoretically proven reinforcement learning–based controller for real-world UAV swarms, addressing the translation challenges from simulation to outdoor deployment beyond WiFi and motion capture systems. The work demonstrates how theoretical control designs must be adapted to real hardware and software constraints.[3]\n\n**Task Addressed:** Trajectory planning and control in decentralized swarm settings\n\n**Learning Paradigm:** Decentralized hierarchical reinforcement learning\n\n**Evaluation Setup:** Real-world outdoor deployment with hardware constraints[3]\n\n**Link:** https://arc.aiaa.org/doi/10.2514/6.2024-2761\n\n---\n\n## 4. Supporting UAVs Swarm Missions by Multi-Agent Reinforcement Learning\n\n**Authors:** Fusco et al.\n\n**Year:** 2025\n\n**Publication Venue:** 2025 Workshop on Computing, Networking and Communications (CNC)\n\n**Main Contribution:** Presents a Multi-Agent Reinforcement Learning (MARL)–based approach for computing optimal coverage paths for large regions by UAV swarms supported by mobile battery swapping stations. The approach optimizes path planning, energy consumption, and battery swapping coordination to maximize operational lifespan while ensuring comprehensive area coverage.[4]\n\n**Task Addressed:** Coverage path planning with energy optimization and coordination\n\n**Learning Paradigm:** Multi-Agent Reinforcement Learning (MARL) with Proximal Policy Optimization (PPO)\n\n**Evaluation Setup:** 3D simulation environment with three UAV agents[4]\n\n**Link:** http://www.conf-icnc.org/2025/papers/p222-fusco.pdf\n\n---\n\n## 5. Enhanced Multi-Agent Coordination Algorithm for Drone Swarm Patrolling\n\n**Authors:** Not fully specified in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Nature Scientific Reports\n\n**Main Contribution:** Proposes an enhanced multi-agent swarm control algorithm (EN-MASCA) combining Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms for the first time to optimize UAV swarm path planning and obstacle avoidance in complex agricultural scenarios. Includes a virtual navigator model to enhance environmental adaptability.[5]\n\n**Task Addressed:** Patrolling, path planning, and obstacle avoidance in complex environments\n\n**Learning Paradigm:** Multi-agent reinforcement learning combining DQN and PPO\n\n**Evaluation Setup:** Simulation environment (specific dimensionality not detailed in excerpt)[5]\n\n**Link:** https://www.nature.com/articles/s41598-025-88145-7\n\n---\n\n## 6. End-to-End Multi-Task Reinforcement Learning–Based UAV Swarm\n\n**Authors:** Not fully specified in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Knowledge-Based Systems (Elsevier)\n\n**Main Contribution:** Proposes an innovative end-to-end multi-task reinforcement learning framework designed to enhance the security and operational stability of UAV swarms.[6]\n\n**Task Addressed:** Multi-task coordination and operational stability\n\n**Learning Paradigm:** End-to-end multi-task reinforcement learning\n\n**Evaluation Setup:** Not detailed in excerpt\n\n**Link:** https://dl.acm.org/doi/10.1016/j.knosys.2025.113390\n\n---\n\n**Note:** The search results provided contain limited bibliographic details for some entries. For complete author lists, abstract details, and full methodological descriptions, direct consultation of the original papers is recommended.",
    "timestamp": "2025-12-23T20:09:29.369236"
  },
  "pico_scalability_and_robustness": {
    "query": "\n    (Multi UAV OR autonomous drones OR UAV swarm OR unmanned aerial vehicle swarm OR autonomous UAV) AND\n    (multi-agent reinforcement learning OR deep reinforcement learning OR reinforcement learning OR deep learning OR neural networks OR MARL OR DRL) AND\n    (scalability OR robustness OR fault tolerance)\n    ",
    "response": "### Relevant Papers (Published June 2024–December 2025)\n\n#### Title: Reinforcement Learning for Decision-Level Interception Prioritization in Swarm Drone Attacks\n- **Authors**: Not specified in available details\n- **Year**: 2025\n- **Publication venue**: arXiv preprint (arxiv.org/html/2508.00641v1)\n- **Main contribution**: Introduces a deep reinforcement learning agent for high-level threat prioritization in swarm drone interception scenarios, formulated as a partially observable Markov decision process (POMDP) within a high-fidelity simulation capturing operational constraints like noisy observations and heterogeneous threats. The approach enables adaptive coordination of multiple effectors for optimal interception without direct control, addressing limitations of rule-based systems in unpredictable swarm attacks. It demonstrates RL's superiority over traditional methods in generalizing to variable swarm behaviors.[1]\n- **Task addressed**: Interception prioritization (coordination and collision avoidance in adversarial swarm defense)\n- **Learning paradigm**: Deep reinforcement learning (single-agent RL for decision-level coordination in multi-UAV defense)\n- **Evaluation setup**: High-fidelity 3D simulation environment\n- **Link**: https://arxiv.org/html/2508.00641v1\n\n#### Title: A Deployable, Decentralized Hierarchical Reinforcement Learning Strategy for Trajectory Planning and Control of UAV Swarms\n- **Authors**: Grant Phillips et al.\n- **Year**: 2024\n- **Publication venue**: AIAA conference (arc.aiaa.org/doi/10.2514/6.2024-2761)\n- **Main contribution**: Presents a decentralized hierarchical RL strategy for UAV swarm trajectory planning and control, adapted from simulation to real-world deployment by addressing hardware constraints like limited communication and computation. It highlights challenges in translating theoretical RL designs to outdoor environments beyond WiFi and motion capture, ensuring stability and performance under real hardware limitations. The work emphasizes robustness and scalability for practical multi-UAV operations.[3]\n- **Task addressed**: Trajectory planning and control (navigation, path planning, collision avoidance)\n- **Learning paradigm**: Decentralized hierarchical reinforcement learning\n- **Evaluation setup**: Real-world outdoor deployment (with prior simulation validation)\n- **Link**: https://arc.aiaa.org/doi/10.2514/6.2024-2761\n\n#### Title: Supporting UAVs Swarm Missions by Multi-Agent Reinforcement Learning\n- **Authors**: Fusco et al. (inferred from PDF filename: p222-fusco.pdf)\n- **Year**: 2025\n- **Publication venue**: 2025 Workshop on Computing, Networking and Communications (CNC), conf-icnc.org\n- **Main contribution**: Develops a MARL-based approach for computing coverage paths in large regions using UAV swarms supported by mobile battery swapping stations, optimizing energy consumption, travel distance, and area coverage while avoiding collisions and overlaps. It addresses scalability challenges in MARL, such as non-stationarity and curse of dimensionality with increasing agent numbers, using algorithms like PPO for decentralized execution. The method enhances efficiency and adaptability in energy-constrained missions through real-time path optimization.[4]\n- **Task addressed**: Coverage path planning (exploration, coordination, energy-efficient cooperation)\n- **Learning paradigm**: Multi-agent reinforcement learning (MARL), with Proximal Policy Optimization (PPO)\n- **Evaluation setup**: Simulation (3 UAV agents tested)\n- **Link**: http://www.conf-icnc.org/2025/papers/p222-fusco.pdf\n\n**Notes on Search Limitations**: Other results [2], [5], [6] mention RL/MARL for UAV swarms (e.g., fission-fusion, patrolling, multi-task security) but lack sufficient bibliographic details (e.g., authors, exact publication dates, or full validation setups) or explicit focus on scalability/robustness/fault tolerance to meet all PICO/constraint criteria without inference. No papers explicitly detail fault tolerance; robustness/scalability is inferred where supported. All selected works involve UAV swarms with experimental validation, prioritizing decentralized/cooperative settings.[1][2][3][4][5][6]",
    "timestamp": "2025-12-23T20:09:36.742463"
  },
  "pico_performance_metrics": {
    "query": "\n    (Multi UAV OR autonomous drones OR UAV swarm OR unmanned aerial vehicle swarm OR autonomous UAV) AND\n    (multi-agent reinforcement learning OR deep reinforcement learning OR reinforcement learning OR deep learning OR neural networks OR MARL OR DRL) AND\n    (performance evaluation OR efficiency OR success rate OR energy efficiency)\n    ",
    "response": "Based on the search results provided, here are the peer-reviewed and preprint academic papers published between June 2024 and December 2025 that satisfy your PICO-based criteria for UAV swarm systems with reinforcement learning:\n\n---\n\n## 1. Reinforcement Learning for Decision-Level Interception of Kamikaze Drone Swarms\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** arXiv preprint (arxiv.org/html/2508.00641v1)\n\n**Main Contribution:** Introduces a decision-level reinforcement learning agent that learns to coordinate multiple effectors for optimal interception prioritization of hostile UAV swarms. The work presents a high-fidelity simulation environment capturing realistic operational constraints and demonstrates RL's capacity to adapt to complex, unpredictable drone swarm scenarios where traditional rule-based systems fail to generalize.[1]\n\n**Task Addressed:** Threat prioritization and interception coordination in swarm-based saturation attacks\n\n**Learning Paradigm:** Deep reinforcement learning with centralized decision-making; formulated as a partially observable Markov decision process (POMDP)[1]\n\n**Evaluation Setup:** High-fidelity simulation environment[1]\n\n**Link:** https://arxiv.org/html/2508.00641v1\n\n---\n\n## 2. Reinforcement Learning–Based UAV Swarm Fission–Fusion with Real-World Data Integrated Validation\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025 (inferred from publication venue)\n\n**Publication Venue:** International Journal of Aerospace Engineering (Wiley)\n\n**Main Contribution:** Presents a reinforcement learning–based approach for UAV swarm fission–fusion dynamics with integrated real-world data validation.[2]\n\n**Task Addressed:** Swarm fission–fusion (dynamic reconfiguration and splitting/merging of swarm formations)\n\n**Learning Paradigm:** Reinforcement learning (specific variant not detailed in excerpt)\n\n**Evaluation Setup:** Real-world data integrated validation[2]\n\n**Link:** https://onlinelibrary.wiley.com/doi/full/10.1155/ijae/7686417\n\n---\n\n## 3. A Deployable, Decentralized Hierarchical Reinforcement Learning Strategy for Trajectory Planning and Control of UAV Swarms\n\n**Authors:** Grant Phillips (and others not fully listed in excerpt)\n\n**Year:** 2024\n\n**Publication Venue:** AIAA conference proceedings (arc.aiaa.org/doi/10.2514/6.2024-2761)\n\n**Main Contribution:** Details implementation of a decentralized, theoretically proven reinforcement learning–based controller for real-world UAV swarms, addressing practical deployment challenges including communication and computational constraints that often break down theoretical assumptions.[3]\n\n**Task Addressed:** Trajectory planning and control in multi-agent swarm systems\n\n**Learning Paradigm:** Decentralized hierarchical reinforcement learning[3]\n\n**Evaluation Setup:** Real-world outdoor deployment beyond WiFi and motion capture systems[3]\n\n**Link:** https://arc.aiaa.org/doi/10.2514/6.2024-2761\n\n---\n\n## 4. Supporting UAV Swarm Missions by Multi-Agent Reinforcement Learning with Mobile Battery Swapping Stations\n\n**Authors:** Fusco (and others; full author list not provided in excerpt)\n\n**Year:** 2025\n\n**Publication Venue:** 2025 Workshop on Computing, Networking and Communications (CNC)\n\n**Main Contribution:** Presents a Multi-Agent Reinforcement Learning (MARL)–based strategy for energy-efficient coverage path planning of large regions by UAV swarms supported by mobile charging stations. The approach optimizes battery swapping, reduces travel distance, and minimizes energy consumption while ensuring comprehensive area coverage.[4]\n\n**Task Addressed:** Coverage path planning with energy efficiency optimization\n\n**Learning Paradigm:** Multi-Agent Reinforcement Learning (MARL); Proximal Policy Optimization (PPO) achieved best performance[4]\n\n**Evaluation Setup:** Simulation framework with three UAV agents[4]\n\n**Link:** http://www.conf-icnc.org/2025/papers/p222-fusco.pdf\n\n---\n\n## 5. Enhanced Multi-Agent Coordination Algorithm for Drone Swarm Patrolling (EN-MASCA)\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Nature Scientific Reports\n\n**Main Contribution:** Proposes an enhanced multi-agent swarm control algorithm (EN-MASCA) combining Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms for the first time to optimize UAV swarm path planning and obstacle avoidance in complex agricultural scenarios, incorporating a virtual navigator model for enhanced environmental adaptability.[5]\n\n**Task Addressed:** Path planning, obstacle avoidance, and patrolling in complex agricultural environments\n\n**Learning Paradigm:** Multi-agent deep reinforcement learning combining DQN and PPO[5]\n\n**Evaluation Setup:** Simulation environment (specific details not provided in excerpt)\n\n**Link:** https://www.nature.com/articles/s41598-025-88145-7\n\n---\n\n## 6. End-to-End Multi-Task Reinforcement Learning–Based UAV Swarm Framework\n\n**Authors:** Not explicitly provided in excerpt\n\n**Year:** 2025\n\n**Publication Venue:** Knowledge-Based Systems (Elsevier)\n\n**Main Contribution:** Proposes an innovative end-to-end multi-task reinforcement learning framework designed to enhance the security and operational stability of UAV swarms across multiple concurrent objectives.[6]\n\n**Task Addressed:** Multi-task learning for UAV swarm operations (specific tasks not detailed in excerpt)\n\n**Learning Paradigm:** End-to-end multi-task reinforcement learning[6]\n\n**Evaluation Setup:** Not specified in excerpt\n\n**Link:** https://dl.acm.org/doi/10.1016/j.knosys.2025.113390\n\n---\n\n**Note:** All six papers meet your core PICO criteria (multi-UAV systems, reinforcement learning interventions, and performance/efficiency outcomes). Papers 1, 3, and 5 explicitly address decentralized or cooperative multi-agent settings. Papers 1, 3, and 2 include real-world or high-fidelity simulation validation. Complete bibliographic details (full author lists, DOIs) were not fully available in the search excerpts provided.",
    "timestamp": "2025-12-23T20:09:51.283295"
  }
}