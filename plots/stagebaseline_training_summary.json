{
  "stage": "baseline",
  "num_agents": 5,
  "total_timesteps": 2200000,
  "reward": {
    "mean": -2.992151287468997,
    "std": 0.5671246648175269,
    "min": -3.4776957035064697,
    "max": -1.4511512517929077,
    "final_value": -3.4776957035064697,
    "initial_value": -1.66334867477417
  },
  "metrics": {
    "policy_loss": {
      "overall_mean": -0.0063552425242960455,
      "std": 0.0010287586694448655,
      "min": -0.009870920609682799,
      "max": -0.005151030933484435,
      "final_value": -0.006231772201135755,
      "initial_value": -0.009870920609682799
    },
    "value_loss": {
      "overall_mean": 0.006131050132998182,
      "std": 0.007852632126271112,
      "min": 0.001744785625487566,
      "max": 0.03364500217139721,
      "final_value": 0.0018489943584427237,
      "initial_value": 0.013528439588844777
    },
    "entropy_loss": {
      "overall_mean": -0.006537949489641257,
      "std": 0.0014278496873063923,
      "min": -0.01192812379449606,
      "max": -0.005007003573700786,
      "final_value": -0.005007003573700786,
      "initial_value": -0.01192812379449606
    },
    "policy_std": {
      "overall_mean": 0.4929192568768155,
      "std": 0.07428274880641669,
      "min": 0.42243158221244814,
      "max": 0.8090997695922851,
      "final_value": 0.42243158221244814,
      "initial_value": 0.8090997695922851
    }
  }
}