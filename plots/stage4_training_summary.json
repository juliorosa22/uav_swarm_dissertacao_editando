{
  "stage": 4,
  "num_agents": 5,
  "total_timesteps": 261000,
  "reward": {
    "mean": -2.2037283702828416,
    "std": 0.17787443039457052,
    "min": -2.9706380367279053,
    "max": -1.8434584140777588,
    "final_value": -2.343076229095459,
    "initial_value": -2.9706380367279053
  },
  "metrics": {
    "policy_loss": {
      "overall_mean": -0.007857233125331074,
      "std": 0.0015671169876987788,
      "min": -0.013179945945739745,
      "max": -0.005767233110964299,
      "final_value": -0.006558744888752699,
      "initial_value": -0.013179945945739745
    },
    "value_loss": {
      "overall_mean": 0.011360362869012973,
      "std": 0.01322346223389929,
      "min": 0.002071446366608143,
      "max": 0.12961673885583877,
      "final_value": 0.007165605109184981,
      "initial_value": 0.12961673885583877
    },
    "entropy_loss": {
      "overall_mean": -0.007358133574498108,
      "std": 0.0018282158450383386,
      "min": -0.014420755952596665,
      "max": -0.0053373319562524555,
      "final_value": -0.0053373319562524555,
      "initial_value": -0.014420755952596665
    }
  }
}