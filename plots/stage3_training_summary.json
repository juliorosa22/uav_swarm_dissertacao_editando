{
  "stage": 3,
  "num_agents": 5,
  "total_timesteps": 300000,
  "reward": {
    "mean": -1.3035223853588105,
    "std": 0.3274815922147994,
    "min": -2.892237663269043,
    "max": -0.7165880799293518,
    "final_value": -1.5250717401504517,
    "initial_value": -2.892237663269043
  },
  "metrics": {
    "policy_loss": {
      "overall_mean": -0.00644508000847418,
      "std": 0.0010818368095451669,
      "min": -0.00886723306030035,
      "max": -0.0033633466460742056,
      "final_value": -0.005589104723185301,
      "initial_value": -0.007855845661833883
    },
    "value_loss": {
      "overall_mean": 0.0512344297207892,
      "std": 0.01724325451884586,
      "min": 0.0029936319217085837,
      "max": 0.14963961392641068,
      "final_value": 0.057478635013103484,
      "initial_value": 0.14963961392641068
    },
    "entropy_loss": {
      "overall_mean": -0.009095982173457742,
      "std": 0.001087778940014324,
      "min": -0.01447683684527874,
      "max": -0.008136010728776455,
      "final_value": -0.008136010728776455,
      "initial_value": -0.01447683684527874
    },
    "policy_std": {
      "overall_mean": 0.6140655820965767,
      "std": 0.07458914274096044,
      "min": 0.5562536060810089,
      "max": 1.0300000667572022,
      "final_value": 0.5562536060810089,
      "initial_value": 1.0300000667572022
    }
  }
}