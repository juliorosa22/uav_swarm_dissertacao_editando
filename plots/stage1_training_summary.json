{
  "stage": 1,
  "num_agents": 4,
  "total_timesteps": 200000,
  "reward": {
    "mean": 0.07068224987015129,
    "std": 0.7828489675134708,
    "min": -3.821071147918701,
    "max": 0.9980819821357727,
    "final_value": -0.3019700050354004,
    "initial_value": -3.821071147918701
  },
  "metrics": {
    "policy_loss": {
      "overall_mean": -0.0056375634156211165,
      "std": 0.0054838930187071176,
      "min": -0.011205493996385485,
      "max": 0.046657840721309185,
      "final_value": -0.005562369013205171,
      "initial_value": -0.011205493996385485
    },
    "value_loss": {
      "overall_mean": 0.012306830170346075,
      "std": 0.020061801996621595,
      "min": 0.0005436987994471565,
      "max": 0.19274179264903069,
      "final_value": 0.03457420878112316,
      "initial_value": 0.19274179264903069
    },
    "entropy_loss": {
      "overall_mean": -0.00650340598593175,
      "std": 0.0018891246614761528,
      "min": -0.014410434756428003,
      "max": -0.005002124002203345,
      "final_value": -0.005002124002203345,
      "initial_value": -0.014410434756428003
    },
    "policy_std": {
      "overall_mean": 0.5438803440332413,
      "std": 0.09309082643730067,
      "min": 0.4711007922887802,
      "max": 1.023818165063858,
      "final_value": 0.4711007922887802,
      "initial_value": 1.023818165063858
    }
  }
}