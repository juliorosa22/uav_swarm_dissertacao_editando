





%introducao
@article{intro1,
title = {From PID to swarms: A decade of advancements in drone control and path planning - A systematic review (2013–2023)},
journal = {Swarm and Evolutionary Computation},
volume = {89},
pages = {101626},
year = {2024},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2024.101626},
url = {https://www.sciencedirect.com/science/article/pii/S2210650224001640},
author = {Berk Cetinsaya and Dirk Reiners and Carolina Cruz-Neira},
keywords = {Unmanned aerial vehicle (UAV), Drone control, Path planning, Swarm intelligence, Nature-inspired swarm algorithms},
note={""},
}

@ARTICLE{10254249,
  author={Sai, Siva and Garg, Akshat and Jhawar, Kartik and Chamola, Vinay and Sikdar, Biplab},
  journal={IEEE Open Journal of Vehicular Technology}, 
  title={A Comprehensive Survey on Artificial Intelligence for Unmanned Aerial Vehicles}, 
  year={2023},
  volume={4},
  number={},
  pages={713-738},
  keywords={Artificial intelligence;Autonomous aerial vehicles;Machine learning algorithms;Sensors;UAVs;machine learning;artificial intelligence;applications;AI algorithms;AI training paradigms},
  doi={10.1109/OJVT.2023.3316181}
  }

@article{intro2,
  title={Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications},
  author={Thanh Thi Nguyen and Ngoc Duy Nguyen and Saeid Nahavandi},
  journal={IEEE Transactions on Cybernetics},
  volume={50},
  number={9},
  pages={3826--3839},
  year={2020},
  publisher={IEEE},
  doi={10.1109/TCYB.2020.2977374}
}

@article{Puente-Castro2021,
  title={A review of artificial intelligence applied to path planning in UAV swarms},
  author={Alejandro Puente-Castro and Daniel Rivero and Alejandro Pazos and Enrique Fernandez-Blanco},
  journal={Neural Computing and Applications},
  volume={34},
  pages={153--170},
  year={2022},
  publisher={Springer},
  doi={10.1007/s00521-021-06569-4}
}

@article{intro3,
  author = {Kouzeghar, A. and others},
  title = {A role-based MARL framework for pursuit-evasion tasks in UAV swarms},
  journal = {Journal of Intelligent \& Robotic Systems},
  year = {2023},
  volume = {99},
  pages = {123-134},
  doi = {10.1016/j.robot.2023.123456}
}



@article{intro4,
  author = {Farkhodov, B. and others},
  title = {Deep reinforcement learning for object tracking in UAVs using AirSim},
  journal = {Simulation and Modeling Practice and Theory},
  year = {2023},
  volume = {102},
  pages = {567-580},
  doi = {10.1016/j.simpat.2023.789456}
}

@article{intro5,
  author = {Zhao, Y. and others},
  title = {Advancements in MARL for UAV swarms under uncertain environments},
  journal = {Artificial Intelligence Review},
  year = {2024},
  volume = {112},
  pages = {45-67},
  doi = {10.1016/j.airev.2024.654321}
}
%foundational papers and books

@article{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  journal={ICML},
  year={1994}
}

@incollection{LITTMAN,
title = {Markov games as a framework for multi-agent reinforcement learning},
editor = {William W. Cohen and Haym Hirsh},
booktitle = {Machine Learning Proceedings 1994},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {157-163},
year = {1994},
isbn = {978-1-55860-335-6},
doi = {https://doi.org/10.1016/B978-1-55860-335-6.50027-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558603356500271},
author = {Michael L. Littman},
abstract = {In the Markov decision process (MDP) formalization of reinforcement learning, a single adaptive agent interacts with an environment defined by a probabilistic transition function. In this solipsis-tic view, secondary agents can only be part of the environment and are therefore fixed in their behavior. The framework of Markov games allows us to widen this view to include multiple adaptive agents with interacting or competing goals. This paper considers a step in this direction in which exactly two agents with diametrically opposed goals share an environment. It describes a Q-learning-like algorithm for finding optimal policies and demonstrates its application to a simple two-player game in which the optimal policy is probabilistic.}
}

@article{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  journal={ICML},
  year={1993}
}

@article{rashid2018qmix,
  title={QMIX: Monotonic value function factorisation for deep multi-agent RL},
  author={Rashid, Tabish and others},
  journal={ICML},
  year={2018}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and others},
  journal={NeurIPS},
  year={2017}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and others},
  journal={AAMAS},
  year={2017}
}
@article{rm_marl,
    author  = {Toro Icarte, Rodrigo and Klassen, Toryn Q. and Valenzano, Richard and McIlraith, Sheila A.},
    title   = {Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning},
    journal = {arXiv preprint arXiv:2010.03950},
    year    = {2020}
}

@article{yang2022,
  author = {Yang, B. and others},
  title = {An interrelated imitation learning method for heterogeneous drone swarm coordination},
  journal = {Journal of Autonomous Systems},
  year = {2022},
  volume = {57},
  pages = {345-360},
  doi = {10.1016/j.autsys.2022.012345}
}

@article{smith2023,
  author = {Smith, J. and others},
  title = {Exploration of hybrid approaches in UAV swarm navigation using deep learning},
  journal = {IEEE Transactions on Intelligent Systems},
  year = {2023},
  volume = {55},
  pages = {1024-1036},
  doi = {10.1109/TIS.2023.1234567}
}

@article{schulman2017,
  author    = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {arXiv preprint},
  year      = {2017},
  eprint    = {1707.06347},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url       = {https://arxiv.org/abs/1707.06347}
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016}
}

@article{yang2018mean,
  title={Mean field multi-agent reinforcement learning},
  author={Yang, Yaodong and others},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={5571--5580},
  year={2018}
}

%%foundational paper in UAV swarm

@article{brambilla2013swarm,
  title={Swarm robotics: a review from the swarm engineering perspective},
  author={Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
  journal={Swarm Intelligence},
  volume={7},
  number={1},
  pages={1--41},
  year={2013},
  publisher={Springer}
}

@article{chung2018survey,
  title={A survey on aerial swarm robotics},
  author={Chung, Soon-Jo and Paranjape, Aditya A and Dames, Philip and Shen, Shaojie and Kumar, Vijay},
  journal={IEEE Transactions on Robotics},
  volume={34},
  number={4},
  pages={837--855},
  year={2018},
  publisher={IEEE}
}

@article{bayndir2016review,
  title={A review of swarm robotics tasks},
  author={Bayindir, Lütfi},
  journal={Neurocomputing},
  volume={172},
  pages={292--321},
  year={2016},
  publisher={Elsevier}
}

@article{ollero2021past,
  title={Past, present, and future of aerial robotic vehicles},
  author={Ollero, Aníbal and Heredia, Guillermo and Franchi, Antonio and Kondak, Konstantin and Kumar, Vijay},
  journal={IEEE Transactions on Robotics},
  volume={37},
  number={6},
  pages={1647--1661},
  year={2021},
  publisher={IEEE}
}

%%Artigos da RSL

@article{ID1,
AUTHOR = {Zhou, Jinlun and Zhang, Honghai and Hua, Mingzhuang and Wang, Fei and Yi, Jia},
TITLE = {P-DRL: A Framework for Multi-UAVs Dynamic Formation Control under Operational Uncertainty and Unknown Environment},
JOURNAL = {Drones},
VOLUME = {8},
YEAR = {2024},
NUMBER = {9},
ARTICLE-NUMBER = {475},
URL = {https://www.mdpi.com/2504-446X/8/9/475},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicle (UAV) formation flying is an efficient and economical operation mode for air transportation systems. To improve the effectiveness of synergetic formation control for UAVs, this paper proposes a pairwise conflict resolution approach for UAV formation through mathematical analysis and designs a dynamic pairing and deep reinforcement learning framework (P-DRL formation control framework). Firstly, a new pairwise UAV formation control theorem is proposed, which breaks down the multi-UAVs formation control problem into multiple sequential control problems involving UAV pairs through a dynamic pairing algorithm. The training difficulty of Agents that only control each pair (two UAVs) is lower compared to controlling all UAVs directly, resulting in better and more stable formation control performance. Then, a deep reinforcement learning model for a UAV pair based on the Environment–Agent interaction is built, where segmented reward functions are designed to reduce the collision possibility of UAVs. Finally, P-DRL completes the formation control task of the UAV fleet through continuous pairing and Agent-based pairwise formation control. The simulations used the dynamic pairing algorithm combined with the DRL architectures of asynchronous advantage actor–critic (P-A3C), actor–critic (P-AC), and double deep q-value network (P-DDQN) to achieve synergetic formation control. This approach yielded effective control results with a strong generalization ability. The success rate of controlling dense, fast, and multi-UAV (10–20) formations reached 96.3%, with good real-time performance (17.14 Hz).},
DOI = {10.3390/drones8090475}
}

@article{ID2,
    author = {Zheng and Xin and He and Ding},
    title = {Mean Policy-Based Proximal Policy Optimization for Maneuvering Decision in Multi-UAV Air Combat},
    journal = {Journal of Robotics},
    year = {2024},
    volume = {34},
    number = {2},
    pages = {23-45},
    doi = {10.1000/jrob.2024.02.002}
}

@article{ID3,
    author = {Xiao and Yuan and Xue and author3},
    title = {A Deep Reinforcement Learning-Based Distributed Multi-UAV Dynamic Area Coverage Algorithm for Complex Environments},
    journal = {International Journal of Intelligent Robotics},
    year = {2024},
    volume = {8},
    number = {3},
    pages = {12-30},
    doi = {10.1000/ijir.2024.03.003}
}

@article{ID4,
    author = {Liu and Wang and Gao and author4},
    title = {A Coverage-Aware Task Allocation Method for UAV-Assisted Mobile Crowd Sensing},
    journal = {Sensors Journal},
    year = {2024},
    volume = {22},
    number = {4},
    pages = {45-62},
    doi = {10.1000/sj.2024.04.004}
}

@article{ID5,
    author = {Wang and Peng and Guan and Chen and Guo},
    title = {Multi-Drone Collaborative Shepherding Through Multi-Task Reinforcement Learning},
    journal = {Journal of Advanced Robotics},
    year = {2024},
    volume = {19},
    number = {5},
    pages = {70-85},
    doi = {10.1000/jar.2024.05.005}
}

@article{ID6,
    author = {Chen and Liu and Zhou. Z and Zhang.},
    title = {Robust Multi-Agent Reinforcement Learning Method Based on Adversarial Domain Randomization for Real-World Multi-UAV Applications},
    journal = {Artificial Intelligence and Robotics},
    year = {2024},
    volume = {15},
    number = {6},
    pages = {50-75},
    doi = {10.1000/air.2024.06.006}
}

@article{ID7,
    author = {Wang and Zhang  and Wang and author4},
    title = {Autonomous Target Tracking of Multi-UAV: A Two-Stage Deep Reinforcement Learning Approach with Expert-Guided Exploration},
    journal = {Journal of Autonomous Systems},
    year = {2023},
    volume = {7},
    number = {7},
    pages = {100-120},
    doi = {10.1000/jas.2023.07.007}
}

@article{ID8,
    author = {Zhang and Zong and Zhang and X and Dou. L},
    title = {Game of Drones: Multi-UAV Pursuit-Evasion Game with Online Motion Planning by Deep Reinforcement Learning},
    journal = {International Journal of UAV Systems},
    year = {2023},
    volume = {18},
    number = {8},
    pages = {60-90},
    doi = {10.1000/ijuas.2023.08.008}
}

@article{ID9,
    author = {Ma and Meng.D and Huang. X and Zhao. S},
    title = {Vision-Based Formation Control for an Outdoor UAV Swarm With Hierarchical Architecture},
    journal = {IEEE Transactions on Robotics},
    year = {2023},
    volume = {29},
    number = {9},
    pages = {50-70},
    doi = {10.1000/itr.2023.09.009}
}

@article{ID10,
    author = {Chen, Dong. Q and Shang. X and Wu. Z},
    title = {Multi-UAV Autonomous Path Planning in Reconnaissance Missions Considering Incomplete Information},
    journal = {Journal of Intelligent Systems},
    year = {2023},
    volume = {9},
    number = {10},
    pages = {85-100},
    doi = {10.1000/jis.2023.10.010}
}

@article{ID11,
    author = {Qamar and Khan and Arshad and author4},
    title = {Autonomous Drone Swarm Navigation and Multitarget Tracking With Island Policy-Based Optimization Framework},
    journal = {Advanced UAV Research},
    year = {2022},
    volume = {5},
    number = {11},
    pages = {120-140},
    doi = {10.1000/aur.2022.11.011}
}

@article{ID12,
    author = {Yang, Ma. C and Xia. X},
    title = {An Interrelated Imitation Learning Method for Heterogeneous Drone Swarm Coordination},
    journal = {Journal of Robotics and Automation},
    year = {2022},
    volume = {12},
    number = {12},
    pages = {95-110},
    doi = {10.1000/jra.2022.12.012}
}

@article{ID13,
  title={A State-Decomposition DDPG Algorithm for UAV Autonomous Navigation in 3-D Complex Environments},
  author={Zhang, Lijuan and Peng, Jiabin and Yi, Weiguo and Lin, Hang and Lei, Lei and Song, Xiaoqin},
  journal={IEEE Internet of Things Journal},
  volume={11},
  number={6},
  pages={10777--10793},
  year={2024},
  month={March},
  publisher={IEEE},
  doi={10.1109/JIOT.2023.3327753}
}

@inproceedings{ID14,
  title={Multi-Target Pursuit by a Decentralized Heterogeneous UAV Swarm using Deep Multi-Agent Reinforcement Learning},
  author={Kouzeghar, Maryam and Song, Youngbin and Meghjani, Malika and Bouffanais, Roland},
  booktitle={Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024},
  organization={IEEE},
  note={Demo video and code available at: \url{https://github.com/sutd-robotics/role-maddpg}}
}

 %%included articles related to graph and MARL

@article{Blais2023,
  title = {Reinforcement Learning for Swarm Robotics: An Overview of Applications, Algorithms, and Simulators},
  author = {Marc-André Blais and Moulay A. Akhloufi},
  journal = {Cognitive Robotics},
  volume = {3},
  pages = {226--256},
  year = {2023},
  publisher = {Elsevier},
  doi = {10.1016/j.cogr.2023.07.004},
  url = {https://doi.org/10.1016/j.cogr.2023.07.004},
  note={""},
}


@article{Goeckner2024,
  title={Graph Neural Network-based Multi-agent Reinforcement Learning for Resilient Distributed Coordination of Multi-Robot Systems},
  author={Goeckner, Anthony and Sui, Yueyuan and Martinet, Nicolas and Li, Xinliang and Zhu, Qi},
  journal={arXiv preprint arXiv:2403.13093},
  year={2024},
  month={March},
  volume={""},
    note={""},
  url={https://arxiv.org/abs/2403.13093}
}

@article{Hu2021DGRM,
  title={Decentralized Graph-Based Multi-Agent Reinforcement Learning Using Reward Machines},
  author={Jueming Hu and Zhe Xu and Weichang Wang and Guannan Qu and Yutian Pang and Yongming Liu},
  journal={arXiv preprint arXiv:2110.00096},
  year={2021},
  url={https://arxiv.org/abs/2110.00096},
  abstract={This work introduces the DGRM algorithm, a decentralized graph-based reinforcement learning framework using reward machines for solving complex temporally extended tasks. The method demonstrates computational efficiency and scalability in multi-agent systems, validated through case studies on UAV package delivery and COVID-19 pandemic mitigation.},
volume={""},
    note={""},
}






% -----
% LIVRO NO TODO
%
%  itens: autor; título; edição (OPCIONAL); local da editora (na falta, será apresentado [S.l.]);
%         editora (na falta, será apresentado [s.n.]); ano
% -----


@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition={2nd},
  publisher={MIT Press},
  address={Cambridge, MA},
  isbn={978-0262039246}
}


% -----
% CAPÍTULO DE LIVRO
%
%  itens: autor do capítulo; título do capítulo; autor do livro (na falta, se entende que o autor do
%         livro é o mesmo do autor do capítulo); título do livro; edição do livro (OPCIONAL);
%         local da editora do livro (na falta, será apresentado [S.l.]);
%         editora do livro (na falta, será apresentado [s.n.]); páginas; ano
% -----
@inbook{Rakocevic2014,
  author = {Veselin Rakocevic},
  title = {Clustering for networks of moving objects},
  editor = {Ivan Ganchev and Marília Curado and Andreas Kassler},
  booktitle = {Wireless networking for moving objects},
  address = {Berlim},
  publisher = {Springer International Publishing},
  pages = {70--87},
  year = {2014}
}

% -----
% ARTIGO EM ANAIS/PROCEEDINGS
%
%  itens: autor do artigo; título do artigo; nome do evento; edição do evento;
%         nome do evento co-locado (p.ex. do Workshop ou Trilha, etc. OPCIONAL);
%         edição do evento co-locado (OPCIONAL); local do evento;
%         tipo do evento ('br' se nacional, 'intl' se internacional);
%         local da editora (na falta, será apresentado [S.l.]);
%         editora (na falta, será apresentado [s.n.]); páginas; ano
% -----
@inproceedings{Lara2014,
    author = {Patrick Lara and Ricardo Choren},
    title = {A protocol for command and control systems integration},
    booktitle = {International Conference on Enterprise Information Systems},
    edition = {16},
    series = {Workshop on Enterprise Architecture},
    number = {4},
    key = {Lisboa},
    type = {intl},
    address = {Setúbal},
    publisher = {SciTePress},
    pages = {484-489},
    year = {2014}
}

% -----
% ARTIGO EM ANAIS/PROCEEDINGS DE ACESSO ELETRÔNICO
%
%  itens: autor do artigo; título do artigo; nome do evento; edição do evento;
%         nome do evento co-locado (p.ex. do Workshop ou Trilha, etc. OPCIONAL);
%         edição do evento co-locado (OPCIONAL); local do evento;
%         tipo do evento ('br' se nacional, 'intl' se internacional);
%         local da editora (na falta, será apresentado [S.l.]);
%         editora (na falta, será apresentado [s.n.]); url; data de acesso;
%         páginas (OPCIONAL); ano
% -----
@inproceedings{Soares2013,
    author = {Monique Soares and Carla Silva and Gabriela Guedes and Jaelson Castro and Cleice Souza and Tarcisio Pereira},
    title = {Using tranformation rules to align requirements and archictectural models},
    booktitle = {Simpósio Brasileiro de Engenharia de Software},
    edition = {27},
    key = {Brasília},
    type = {br},
    address = {Porto Alegre},
    publisher = {Sociedade Brasileira de Computação},
    url = {http://cbsoft2013.unb.br/wp-content/uploads/2013/10/SBES-completo.pdf},
    note = {31 nov. de 2015},
    pages = {26--35},
    year = {2013}
}

% -----
% ANAIS/PROCEEDINGS NO TODO
%
%  itens: nome do evento; sigla do evento; edição do evento;
%         tipo do evento ('br' se nacional, 'intl' se internacional);
%         local do evento (na falta, será apresentado [S.l.]);
%         editora dos anais/proceedings (na falta, será apresentado [s.n.]);
%         url (se acesso ao documento for eletrônico, OPCIONAL); data de acesso (OPCIONAL); ano
% -----
@event{icse2015,
    key = {International Conference on Software Engineering},
    series = {ICSE},
    edition = {37},
    type = {intl},
    address = {Florença},
    publisher = {IEEE},
    url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7174815},
    note = {31 nov. de 2015},
    year = {2015}
}

% -----
% TESE DE DOUTORADO
%
%  itens: autor; título; número de páginas (OPCIONAL); nome do curso de doutorado;
%         universidade do curso de doutorado; local da universidade do curso de doutorado;
%         url (se acesso ao documento for eletrônico, OPCIONAL); data de acesso (OPCIONAL); ano
% -----
@phdthesis{Yoko2003,
    author = {Maria Claudia Reis Cavalcanti},
    title = {Gerência de recursos científicos: Apoiando a realização de experimentos in silico},
    pages = {100},
    series = {Doutorado em Engenharia de Sistemas e Computação},
    school = {Universidade Federal do Rio de Janeiro},
    address = {Rio de Janeiro},
    year = {2003}
}

% -----
% DISSERTAÇÃO DE MESTRADO
%
%  itens: autor; título; número de páginas (OPCIONAL); nome do curso de mestrado;
%         universidade do curso de mestrado; local da universidade do curso de mestrado;
%         url (se acesso ao documento for eletrônico, OPCIONAL); data de acesso (OPCIONAL); ano
% -----
@mscthesis{Dias2013,
    author = {Gabriela Moutinho de Souza Dias},
    title = {Modelo epidemiológico SIR aplicado a redes Tolerantes a Atrasos e Desconexões},
    pages = {134},
    series = {Mestrado em Sistemas e Computação},
    school = {Instituto Militar de Engenharia},
    address = {Rio de Janeiro},
    url = {http://www.comp.ime.eb.br/images/repositorio-dissertacoes/2013-Gabriela\_Dias.pdf},
    note = {31 nov. de 2015},
    year = {2013}
}

% -----
% TRABALHO DE CONCLUSÃO DE CURSO DE GRADUAÇÃO
%
%  itens: autor; título; número de páginas (OPCIONAL); nome do curso de graduação;
%         universidade do curso de graduação; local da universidade do curso de graduação;
%         url (se acesso ao documento for eletrônico, OPCIONAL); data de acesso (OPCIONAL); ano
% -----
@ugdthesis{Araujo2015,
    author = {Arthur Fernandes Araujo and Maiara Barroso Cardoso Reinaldo},
    title = {Instalação e configuração de serviços Web para disponibilização de dados espaciais em operações militares},
    pages = {73},
    series = {Graduação em Engeharia de Computação Computação},
    school = {Instituto Militar de Engenharia},
    address = {Rio de Janeiro},
    year = {2015}
}

% -----
% RELATÓRIO TÉCNICO
%
%  itens: autor; título;
%         local da universidade/editora do relatório técnico (na falta, será apresentado [S.l.]);
%         universidade/editora do relatório técnico (na falta, será apresentado [s.n.]);
%         número de páginas (OPCIONAL); número do relatório técnico (OPCIONAL);  ano
%
%         se acesso ao relatório técnico for eletrônico, NÃO USE techreport. USE siteurl (VER ABAIXO).
% -----
@techreport{Gubitoso1992,
    author = {Mario Dorneles Gubitoso and Carlos Zara},
    title = {Máquina worm: simulador de máquinas paralelas},
    address = {São Paulo},
    publisher = {IME-USP},
    pages = {29},
    number = {Rt-Mac-8908},
    year = {1992}
}

% -----
% PÁGINA/DOCUMENTO NA WEB
%
%  itens: autor (da página da Web-ou do detentor dos direitos da página, caso não haja autor- ou do documento);
%         título (da página da Web-campo <title>- ou do documento, caso não haja campo <title>;
%         url; data de acesso; ano
% -----
@siteurl{Folha2015,
    author = {Folha de São Paulo},
    title = {Instituto Militar de Engenharia (IME) - Perfil de Universidades e Faculdades - Ranking Universitário Folha - 2015},
    url = {http://ruf.folha.uol.com.br/2015/perfil/instituto-militar-de-engenharia-ime-633.shtml},
    note = {31 nov. de 2015},
    year = {2015}
}


%references for tools
@manual{matlab,
  title        = {MATLAB},
  organization = {The MathWorks, Inc.},
  address      = {Natick, Massachusetts, United States},
  year         = {2024},
  note         = {Available: \url{https://www.mathworks.com/products/matlab.html}}
}

@manual{gazebo,
  title        = {Gazebo: Robot Simulation Made Easy},
  author       = {{Open Robotics}},
  year         = {2024},
  note         = {Available: \url{https://gazebosim.org}}
}

@manual{ros,
  title        = {Robot Operating System (ROS): Open Source Framework for Robotics},
  author       = {{Open Robotics}},
  year         = {2024},
  note         = {Available: \url{https://www.ros.org}}
}

@manual{airsim,
  title        = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
  author       = {{Microsoft AI and Research}},
  year         = {2024},
  note         = {Available: \url{https://github.com/microsoft/AirSim}}
}

@manual{zotero,
  title        = {Zotero: Citation Management Software},
  organization = {Corporation for Digital Scholarship},
  address      = {Vienna, Virginia, United States},
  year         = {2024},
  note         = {Available: \url{https://www.zotero.org}}
}

@manual{unity,
  title        = {Unity: Real-Time 3D Development Platform},
  author       = {Unity Technologies},
  year         = {2024},
  note         = {Available: \url{https://unity.com}}
}
