
\chapter{Introdu\c{c}\~{a}o}
\label{introducao}
% #TXT_INTRODUCAO
% \textcolor{RedOrange}{Na introdução devem ser expostos o tema do trabalho, a relevância do tema, uma breve citação sobre os trabalhos relacionados ao tema, o problema a ser abordado (que deve resultar de uma breve descrição das limitações dos trabalhos relacionados apresentados) e o objetivo geral do trabalho (responder a pergunta ``onde você quer chegar com este trabalho?'').}
Veículos Aéreos Não Tripulados (VANTs) ou \textit{Unmanned Aerial Vehicles} (UAVs), comumente conhecidos como drones, revolucionaram uma ampla gama de aplicações, desde monitoramento e missões de busca e resgate até agricultura e logística. Sua capacidade de operar autonomamente em ambientes diversos tornou-os indispensáveis em domínios civis e militares. Ao longo dos anos, os sistemas de VANTs evoluíram de dispositivos simples controlados remotamente para enxames altamente inteligentes e cooperativos, capazes de tomar decisões complexas.
No setor militar, os enxames de VANTs possibilitam missões de reconhecimento, vigilância e ataque cooperativo, reduzindo riscos para tropas e aumentando a eficácia operacional. Contudo para habilitar o controle coordenado das ações dos agentes VANTs dentro do enxame, torna-se necessário o desenvolvimento de técnicas mais robustas capazes de lidar com ambientes dinâmicos e complexos que as missões exigem.


\section{Contextualização}

O controle de UAVs tem evoluído significativamente ao longo do tempo.
No  trabalho \citeonline{intro1} fornece uma visão abrangente da evolução dos métodos de controle para sistemas de VANTs. O estudo destaca a transição de controladores PID clássicos para abordagens modernas baseadas em IA, incluindo aprendizado por reforço (RL). Com a crescente capacidade de processamento computacional, os UAVs passaram a incorporar técnicas de aprendizado de máquina e aprendizado por reforço profundo (\textbf{Deep Reinforcement Learning} - DRL), permitindo controle adaptativo e maior autonomia em operações de enxame. 

Complementando essa evolução, estudos como \citeonline{intro3,intro4}, abordam técnicas de Aprendizado por Reforço Multiagente (\textit{Multi-Agent Reinforcement Learning} - MARL) explorando sua capacidade de aprimorar a coordenação em enxames ao abordar desafios como: não estacionariedade e observabilidade parcial. Técnicas de MARL melhoram a escalabilidade e a autonomia em enxames de VANTs ao permitir tomada de decisão descentralizada. Contudo, o estudo ressalta uma lacuna persistente entre simulação e implantação prática, onde variabilidade ambiental e limitações de hardware introduzem desafios não abordados em ambientes simulados \cite{intro2}.







\section{Motivação e Justificativa}

Apesar dos avanços no poder computacional dos hardwares e no desenvolvimento dos algoritmos de IA, os frameworks existentes de MARL ainda enfrentam desafios significativos relacionados à não-estacionariedade e escalabilidade. Essas dificuldades tornam-se especialmente críticas à medida que o tamanho do enxame aumenta ou quando os agentes operam em espaços de estados de alta dimensão. Tais limitações são particularmente sensíveis em operações militares, onde o enxame deve executar múltiplas tarefas simultaneamente, como rastrear alvos móveis, evitar colisões com obstáculos, otimizar o consumo de energia e manter a formação da frota. Esses cenários apresentam um alto grau de complexidade, pois exigem um processo de tomada de decisão hierárquico e descentralizado por parte dos agentes, tornando essencial o desenvolvimento de estratégias de controle mais robustas e adaptativas.

Este trabalho propõe a integração de Máquinas de Recompensa (\textit{Reward Machines} - RMs) com algoritmos de aprendizado multiagente (MARL), visando o projeto de funções de recompensas estruturadas e hierárquicas para enxames de VANTs. Ao decompor missões complexas (por exemplo, rastreamento de alvos) em subtarefas modulares, o framework alinha agentes descentralizados aos objetivos globais, ao mesmo tempo em que enfrenta desafios como escalabilidade e observabilidade parcial. Essa abordagem se baseia em inovações recentes em aprendizado por reforço apresentados em \cite{rm_marl}, ao mesmo tempo em que aborda desafios reais enfrentados por enxames em aplicações militares e logísticas.



Esta dissertação enquadra-se na área de Ciência da Computação em conformidade com a Necessidade de Conhecimento 01M2024 da Portaria Nº 007 do Departamento de Ciência e Tecnologia do Exército Brasileiro, em 27 de Janeiro de 2023. 
% #TXT_MOTIVACAO

% \textcolor{RedOrange}{Apresentar os motivos que levaram \`{a} pesquisa e a sua importância enquadrando-a em uma linha de pesquisa do Programa.}


\section{Objetivos da Dissertação}

\subsection{Objetivo Geral}
\textbf{
Investigar e avaliar a integração de máquinas de recompensa ao processo de
treinamento de algoritmos de aprendizado por reforço multiagente, como forma
de aprimorar a modelagem da função de recompensa em abordagens de controle
descentralizado de enxames de veículos aéreos não tripulados, aplicadas a
tarefas de navegação cooperativa.}

\subsection{Objetivos Específicos}

\begin{enumerate}
    \item Integrar máquinas de recompensa a algoritmos de aprendizado por
    reforço multiagente com execução descentralizada, aplicados ao controle
    de enxames de veículos aéreos não tripulados em ambiente simulado.

    \item Analisar o impacto da utilização de máquinas de recompensa no
    comportamento de coordenação e na estabilidade do aprendizado dos
    agentes ao longo de diferentes estágios da tarefa.

    \item Desenvolver um ambiente de simulação tridimensional para o
    treinamento e avaliação de agentes autônomos VANT, utilizando
    simuladores e bibliotecas consolidadas na área de aprendizado por
    reforço profundo.

    \item Avaliar o desempenho dos agentes treinados em missões de navegação
    cooperativa e rastreamento de alvos em ambientes simulados, por meio de
    métricas quantitativas e análise qualitativa dos comportamentos
    emergentes.
\end{enumerate}

\section{Contribuições do Trabalho}

    As principais contribuições deste trabalho são:

    \begin{itemize}
        \item Proposição e implementação de uma abordagem baseada na integração
        de máquinas de recompensa a algoritmos de aprendizado por reforço
        multiagente, permitindo a decomposição estruturada de tarefas complexas
        em subtarefas para controle de enxames de VANTs.

        \item Avaliação empírica do uso de máquinas de recompensa em tarefas de
        navegação cooperativa e rastreamento de alvos em ambientes simulados,
        evidenciando seu impacto no comportamento e na estabilidade do processo
        de aprendizado.

        \item Desenvolvimento de um ambiente de simulação tridimensional,
        extensível e modular, para treinamento e avaliação de agentes MARL
        aplicados a enxames de veículos aéreos não tripulados.
    \end{itemize}

\section{Estrutura da Dissertação}
Os próximos capítulos deste trabalho, estão estruturados da seguinte forma:
\begin{itemize}
    \item \textbf{Capítulo 2 - Fundamentação Teórica}: Apresentação dos conceitos fundamentais para o desenvolvimento da dissertação.
    
    \item \textbf{Capítulo 3 - Trabalhos Relacionados}: Apresentação dos trabalhos relacionados encontrados durante a revisão sistemática da literatura.
    \item \textbf{Capítulo 4 - Desenvolvimento}: Descrição detalhada do trabalho desenvolvido, incluindo metodologia, ferramentas e técnicas utilizadas.
    \item \textbf{Capítulo 5 - Resultados}: Descrição dos resultados obtidos, discussao e análise crítica dos mesmos e comparação com o estado da arte.
    \item \textbf{Capítulo 6 - Conclusão}: Conclusão e considerações do trabalho.
\end{itemize}

